{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YWb8195s8HJz"
   },
   "source": [
    "# Homework Week 4\n",
    "\n",
    "### Context\n",
    "- Preprocessing\n",
    "- Classification & Regression Model\n",
    "- Cross Validation + OOF Ensemble\n",
    "- Submit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_ZltNAb-8HJ0"
   },
   "source": [
    "#### 프로젝트 안내 사항\n",
    "- 매 주차마다 주어지는 요구사항에 맞게 과제를 진행하시다보면, 어느샌가 완성되어 있는 프로젝트 코드를 마주보게 되실겁니다.\n",
    "- 또한, 팀을 꾸려 서로 의견을 공유하고 좋은 결과를 얻고 싶은 수강생들에 한해 프로젝트 팀을 최대 3인으로 꾸리는 것을 도와드리겠습니다. \n",
    "    - 과제는 개인별로 작성하셔야하고 피드백도 개인으로 해드릴 예정입니다. 프로젝트 팀은 서로 다른 의견을 공유하고 실제 경진대회 진행 시 협업하는 능력을 기르기 위함입니다. \n",
    "    - 팀을 꾸리지 않는다고 수강 시에 배우는 부분에 대해 불이익이 생기지 않도록 최대한 노력하겠습니다. 수강생 분들도 적극적으로 참여 부탁드리겠습니다.\n",
    "    - 질문은 반드시 저에게 해주세요. 팀이라고 서로 이끌고 가야할 의무는 없습니다.\n",
    "- 단순히 요구된 사항을 작성하는 것이 아니라, 기존 대회 페이지에 공개되어있는 아이디어 혹은 코드를 가져와 이해하고 실제로 구현해보길 추천드립니다. 내용이 어렵거나 구현이 어려운 경우 도움 요청 부탁드립니다. <br> 대회는 혼자하는것이 아닙니다. 팀 혹은 같은 대회에 참가하고 있는 인원들끼리 토론을 통해 정보를 주고 받습니다.\n",
    "- 어떤 전처리 방법 혹은 기법을 사용할 때 하는 것이 좋을지에 대한 질문보다는 직접 실험을 해보고, 결과에 대해 분석을 진행해보세요. 분석된 결과에 대해 의문이 생기는 경우에 질문하는 것이 더 많이 배울 수 있습니다.\n",
    "- 개인적으로 공부는 자기 자신이 해야한다고 생각합니다. 제가 전달해드리는 것만 받아들이기 보다는 여러 기법을 실험해보고 의문을 가지며, 스스로 내가 무엇을 알고 무엇을 모르는지 깨닫는 것이 중요합니다.\n",
    "\n",
    "#### 과제 제약사항\n",
    "Numpy, Pandas, Scikit-learn 함수 및 사용법 대한 질문을 받지 않겠습니다. 실제로 대회나 현업에서 프로젝트를 진행하다보면 검색 혹은 라이브러리의 문서를 보면서 진행합니다.<br>\n",
    "처음에는 함수의 종류를 찾거나 사용법을 찾는일이 어려울 수 있지만, 익숙해지셔야 하는 부분이기 때문에 이러한 제약을 걸게 되었습니다. 검색을 어떤 키워드로 해야할지 모를 경우에는 도와드리겠습니다.<br>\n",
    "질문을 전혀 받지 않겠다는 의미가 아닙니다. 단일 함수 종류 및 사용법에 대한 질문을 받지 않겠다 라는 의미입니다. 프로젝트 진행 시 필요한 기능을 스스로 찾을 수 있도록 훈련하는 과정입니다.\n",
    "\n",
    "#### 참고 자료\n",
    "- Numpy Documentation: https://numpy.org/doc/stable/\n",
    "- Pandas Documentation: https://pandas.pydata.org/docs/reference/index.html\n",
    "- Scikit-learn Documentation: https://scikit-learn.org/stable/user_guide.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3sR6ct6u8HJ1"
   },
   "source": [
    "### 과제 설명\n",
    "- 2, 3주차 과제로 진행한 분류, 회귀 프로젝트 코드에 k-Fold Cross Validation, OOF Ensemble 까지 적용해보는것이 이번 과제의 목표입니다.\n",
    "    - 수강생 분께서 작성하신 코드에 이어서 작성하시면 됩니다. 물론 피드백 받은 내용 및 과제 리뷰 강의 코드를 참고하여 작성하셨던 과제 코드를 깔끔하게 수정하시고, 진행하시기 바랍니다.\n",
    "- 이번 과제에서는 XGBoost, LightGBM 2개 모델만 사용합니다. 가능하다면 코랩 환경에서 GPU로 연산하여 모든 데이터를 학습해보세요. \n",
    "    - GPU를 사용하실 수 있다면, XGBoost와 LightGBM의 기능 중 하나인 Early Stopping 기능도 활용해보세요. LightGBM도 완전히 동일하니 모델 이름만 변경해서 사용하시면 됩니다.\n",
    "    \n",
    "    \n",
    "        예제 코드)\n",
    "        model = XGBClassifier(n_estimators=20000,     # Early Stopping 기능을 사용하기 때문에 높게 줍니다.\n",
    "                              random_state= ,         # 원하는 숫자 넣으세요.\n",
    "                              tree_method='gpu_hist', # GPU 연산 옵션\n",
    "                              n_jobs= ,               # CPU 개수 - 1로 입력하세요.\n",
    "                              )\n",
    "        model.fit(x_train, y_train,\n",
    "                  eval_set = [[x_valid, y_valid]], # eval_metric으로 평가할 평가 데이터 입니다.\n",
    "                  eval_metric = ,                  # 평가에 맞는 메트릭 함수 ex)\"logloss\", \"mae\" (공식 문서 확인하시고, 지원하는 메트릭으로 입력해주세요. )\n",
    "                  early_stopping_rounds = ,        # 얼마나 기다릴지에 대한 횟수, 주로 500, 1000 정도합니다.\n",
    "                  verbose = 100,                   # 100번에 한번 씩 결과를 출력해줍니다.\n",
    "                  )\n",
    "                  \n",
    "- 가능한 가장 깔끔한 코드로 작성해보세요. \n",
    "\n",
    "## 월간 데이콘 2회 (분류, 2주차 과제 ~ )\n",
    "\n",
    "#### 사용할 데이터 경로\n",
    "1. data/MDC02/..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IpW-pxsNUOx1"
   },
   "outputs": [],
   "source": [
    "# 데이터 불러오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LB81xWj-8HJ1"
   },
   "source": [
    "#### 1. 전처리\n",
    "- 2주차 과제 전처리 코드\n",
    "    - 4주차 강의 자료와 동일하게 전처리 코드는 함수로 작성하셔야합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wds6bv8sUOx4"
   },
   "outputs": [],
   "source": [
    "# 2주차 과제 전처리 함수\n",
    "def preprocess_2nd(x_train, x_valid, x_test):\n",
    "    tmp_x_train = x_train.copy()\n",
    "    tmp_x_valid = x_valid.copy()\n",
    "    tmp_x_test  = x_test.copy()\n",
    "    \n",
    "    #... \n",
    "    \n",
    "    return tmp_x_train, tmp_x_valid, tmp_x_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wvU9q9rJ8HJ7"
   },
   "source": [
    "#### 2. 모델 검증 + OOF 앙상블\n",
    "- 2주차 과제 모델 사용 코드에서 XGBoost, LightGBM 2개 모델만 사용해서 모델을 검증하고, 그 중 좋은 모델을 선택하여 OOF 앙상블을 해보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xrCPwhA0UOx6"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import # KFold일지 StratifiedKFold를 사용해야하는지 고민해보세요.\n",
    "skf = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bp026iFQUOx8"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "\n",
    "val_scores = list()\n",
    "oof_pred = np.zeros()\n",
    "\n",
    "for i, (trn_idx, val_idx) in enumerate(skf.):\n",
    "    x_train, y_train = \n",
    "    x_valid, y_valid = \n",
    "    \n",
    "    # 전처리\n",
    "    x_train, x_valid, x_test = \n",
    "    \n",
    "    # 모델 정의\n",
    "    clf = \n",
    "    \n",
    "    # 모델 학습\n",
    "    clf.\n",
    "\n",
    "    # 훈련, 검증 데이터 Log Loss 확인\n",
    "    trn_logloss = \n",
    "    val_logloss = \n",
    "    print('{} Fold, train Log Loss : {:.4f}4, validation Log Loss : {:.4f}'.format(i, trn_logloss, val_logloss))\n",
    "    \n",
    "    val_scores.append(val_logloss)\n",
    "    \n",
    "    # Log Loss니까 각 행의 확률 값의 합은 1이 되어야 합니다. 그냥 더하시면 확률 값의 합은 k만큼 되겠죠?\n",
    "    oof_pred += \n",
    "    \n",
    "\n",
    "# 교차 검증 Log Loss 평균 계산하기\n",
    "print('Cross Validation Score : {:.4f}'.format(np.mean(val_scores)))\n",
    "\n",
    "# OOF valid Log Loss 계산하기\n",
    "print('OOF Validation Score : {:.4f}'.format()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ah3OSIGxUOx-"
   },
   "source": [
    "#### 3. 제출 파일 생성 및 제출해보기\n",
    "주어진 `sample_submission.csv` 파일의 규칙에 맞게 결과 파일을 생성하고,<br>\n",
    "[다음 페이지](https://newfront.dacon.io/competitions/official/235573/overview/)에 들어가 결과를 제출해보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yXV1S4wPUOx_"
   },
   "outputs": [],
   "source": [
    "# 주석 해제 후 진행하시면 됩니다.\n",
    "submit_path = join('data', join('MDC02', 'sample_submission.csv'))\n",
    "submit = pd.read_csv(submit_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rtrKFXGtUOyB"
   },
   "outputs": [],
   "source": [
    "submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gqFa5fJrUOyD"
   },
   "outputs": [],
   "source": [
    "# pred 변수는 반드시 각 클래스의 확률 값을 가지고 있어야 합니다. 라벨 변수인 type 변수는 반드시 LabelEncoder를 사용해 라벨 인코딩을 진행합니다.\n",
    "# 각 클래스를 예측한 확률 값은 가진 pred Numpy array와 LabelEncoder 객체의 .classes_ 속성을 이용해 df_pred DataFrame을 생성합니다.\n",
    "df_pred = pd.DataFrame(pred, columns=le.classes_)\n",
    "\n",
    "# submit DataFrame의 컬럼을 가지고 df_pred DataFrame을 컬럼 인덱싱 하여 맞는 컬럼에 값을 집어 넣습니다.\n",
    "# 지정한 파일 이름으로 결과가 csv 파일로 저장됩니다. index=False 조건은 csv 출력 시 인덱스도 같이 출력할 것인지를 지정하는 값인데, 인덱스는 필요없으니 False로 놓습니다.\n",
    "submit_file_name = 'first_submit.csv'\n",
    "submit.loc[:, submit.columns[1:]] = df_pred[submit.columns[1:]]\n",
    "submit.to_csv(submit_file_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rKIFcc11UOyE"
   },
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uLMfWWSfUOyF"
   },
   "source": [
    "## 월간 데이콘 1회 (회귀, 3주차 과제 ~ )\n",
    "\n",
    "#### 사용할 데이터 경로\n",
    "1. data/MDC01/..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IDvO1jt9UOyF"
   },
   "outputs": [],
   "source": [
    "# 데이터 불러오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fHhpFCmhUOyH"
   },
   "source": [
    "#### 1. 전처리\n",
    "- 3주차 과제 전처리 코드\n",
    "    - 4주차 강의 자료와 동일하게 전처리 코드는 함수로 작성하셔야합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1wmB0ip5UOyH"
   },
   "outputs": [],
   "source": [
    "# 3주차 과제 전처리 함수\n",
    "def preprocess_3nd(x_train, x_valid, x_test):\n",
    "    tmp_x_train = x_train.copy()\n",
    "    tmp_x_valid = x_valid.copy()\n",
    "    tmp_x_test  = x_test.copy()\n",
    "    \n",
    "    #... \n",
    "    \n",
    "    return tmp_x_train, tmp_x_valid, tmp_x_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DtNZlE58UOyJ"
   },
   "source": [
    "#### 2. 모델 검증 + OOF 앙상블\n",
    "- 3주차 과제 모델 사용 코드에서 XGBoost, LightGBM 2개 모델만 사용해서 모델을 검증하고, 그 중 좋은 모델을 선택하여 OOF 앙상블을 해보세요.\n",
    "    - 가능하다면 코랩 환경에서 GPU 연산으로 해보시길 추천드립니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2SWCCrWdUOyJ"
   },
   "source": [
    "#### 2-1. Scikit-learn API, MultiOutPutModel\n",
    "- 3주차 과제에서는 4개 라벨에 대해 4개의 모델을 생성했습니다. Scikit-learn에서 지원하는 MuliOutputModel 클래스를 사용하면 코드 작성은 모델 하나지만, 실제로는 여러개의 모델을 학습할 수 있습니다.  \n",
    "    \n",
    "        예제 코드)\n",
    "        from sklearn.multioutput import MultiOutputRegressor\n",
    "        model = MultiOutputRegressor(RandomForest())\n",
    "        model.fit(x_train, y_train)     # 여기에서 y_train은 layer_1, layer_2, layer_3, layer_4로 구성된 4개 컬럼을 가진 DataFrame 입니다.\n",
    "        y_pred = model.predict(x_valid) # y_pred는 (x_valid 행의 수, 라벨의 수)로 이루어진 출력이 나오게 됩니다. \n",
    "        \n",
    "        \n",
    "- 하지만, 이 기능을 사용하면 XGBoost나 LightGBM의 Early Stopping 기능을 사용할 수 없으므로, 좋다고 생각하는 방식으로 작성하세요.\n",
    "    - 좋은 성능을 내려면 당연히 각 라벨에 대해 따로따로 만드셔야합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pX03WGCtUOyJ"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import # KFold일지 StratifiedKFold를 사용해야하는지 고민해보세요.\n",
    "kf = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MS4CAMtfUOyM"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "\n",
    "val_scores = list()\n",
    "oof_pred = np.zeros()\n",
    "\n",
    "for i, (trn_idx, val_idx) in enumerate(kf.):\n",
    "    x_train, y_train = \n",
    "    x_valid, y_valid = \n",
    "    \n",
    "    # 전처리\n",
    "    x_train, x_valid, x_test = \n",
    "    \n",
    "    # 모델 정의\n",
    "    regr = \n",
    "    \n",
    "    # 모델 학습\n",
    "    regr.\n",
    "\n",
    "    # 훈련, 검증 데이터 MAE 확인\n",
    "    trn_mae = \n",
    "    val_mae = \n",
    "    print('{} Fold, train MAE : {:.4f}4, validation MAE : {:.4f}'.format(i, trn_mas, val_mae))\n",
    "    \n",
    "    val_scores.append(val_mae)\n",
    "    \n",
    "    # MAE니까 Fold 전체의 평균으로 만들어야겠죠?\n",
    "    oof_pred += \n",
    "    \n",
    "\n",
    "# 교차 검증 Log Loss 평균 계산하기\n",
    "print('Cross Validation Score : {:.4f}'.format(np.mean(val_scores)))\n",
    "\n",
    "# OOF valid MAE 계산하기\n",
    "print('OOF Validation Score : {:.4f}'.format()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IJvqWiQC8HJ_"
   },
   "source": [
    "#### 3. 제출 파일 생성 및 제출해보기\n",
    "주어진 `sample_submission.csv` 파일의 규칙에 맞게 결과 파일을 생성하고,<br>\n",
    "[다음 페이지](https://newfront.dacon.io/competitions/official/235554/overview/)에 들어가 결과를 제출해보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WbvM5gcY8HKA"
   },
   "outputs": [],
   "source": [
    "# 주석 해제 후 진행하시면 됩니다.\n",
    "submit_path = join('data', join('MDC01', 'sample_submission.csv'))\n",
    "submit = pd.read_csv(submit_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d4xBZyVKUOyP"
   },
   "outputs": [],
   "source": [
    "y_test_layer1 = \n",
    "y_test_layer2 = \n",
    "y_test_layer3 = \n",
    "y_test_layer4 ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FZBe-K8J8HKD"
   },
   "outputs": [],
   "source": [
    "# y_test_layer_1, y_test_layer_2, y_test_layer_3, y_test_layer_4는 가장 성능이 좋은 모델의 4개 라벨에 대한 예측 값을 담고 있습니다.\n",
    "submit['layer_1'] = y_test_layer1\n",
    "submit['layer_2'] = y_test_layer2\n",
    "submit['layer_3'] = y_test_layer3\n",
    "submit['layer_4'] = y_test_layer4\n",
    "\n",
    "# 지정한 파일 이름으로 결과가 csv 파일로 저장됩니다. index=False 조건은 csv 출력 시 인덱스도 같이 출력할 것인지를 지정하는 값인데, 인덱스는 필요없으니 False로 놓습니다.\n",
    "submit_file_name = 'first_submit.csv'\n",
    "submit.to_csv(submit_file_name, index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "HW_04.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
